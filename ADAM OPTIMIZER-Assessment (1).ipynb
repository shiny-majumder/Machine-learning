{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "extensive-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import asarray\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sitting-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "def objective(x, y):\n",
    "\treturn x**2.0 + y**2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "monetary-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of objective function\n",
    "def derivative(x, y):\n",
    "\treturn asarray([x * 2.0, y * 2.0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "agreed-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent algorithm with adam\n",
    "def adam(objective, derivative, bounds, n_iter, alpha, beta1, beta2, eps=1e-8):\n",
    "\t# generate an initial point\n",
    "\tx = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "\tscore = objective(x[0], x[1])\n",
    "\t# initialize first and second moments\n",
    "\tm = [0.0 for _ in range(bounds.shape[0])]\n",
    "\tv = [0.0 for _ in range(bounds.shape[0])]\n",
    "\t# run the gradient descent updates\n",
    "\tfor t in range(n_iter):\n",
    "\t\t# calculate gradient g(t)\n",
    "\t\tg = derivative(x[0], x[1])\n",
    "\t\t# build a solution one variable at a time\n",
    "\t\tfor i in range(x.shape[0]):\n",
    "\t\t\t# m(t) = beta1 * m(t-1) + (1 - beta1) * g(t)\n",
    "\t\t\tm[i] = beta1 * m[i] + (1.0 - beta1) * g[i]\n",
    "\t\t\t# v(t) = beta2 * v(t-1) + (1 - beta2) * g(t)^2\n",
    "\t\t\tv[i] = beta2 * v[i] + (1.0 - beta2) * g[i]**2\n",
    "\t\t\t# mhat(t) = m(t) / (1 - beta1(t))\n",
    "\t\t\tmhat = m[i] / (1.0 - beta1**(t+1))\n",
    "\t\t\t# vhat(t) = v(t) / (1 - beta2(t))\n",
    "\t\t\tvhat = v[i] / (1.0 - beta2**(t+1))\n",
    "\t\t\t# x(t) = x(t-1) - alpha * mhat(t) / (sqrt(vhat(t)) + eps)\n",
    "\t\t\tx[i] = x[i] - alpha * mhat / (sqrt(vhat) + eps)\n",
    "\t\t# evaluate candidate point\n",
    "\t\tscore = objective(x[0], x[1])\n",
    "\t\t# report progress\n",
    "\t\tprint('>%d f(%s) = %.5f' % (t, x, score))\n",
    "\treturn [x, score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vanilla-significance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0 f([-0.14595599  0.42064899]) = 0.19825\n",
      ">1 f([-0.12613855  0.40070573]) = 0.17648\n",
      ">2 f([-0.10665938  0.3808601 ]) = 0.15643\n",
      ">3 f([-0.08770234  0.3611548 ]) = 0.13812\n",
      ">4 f([-0.06947941  0.34163405]) = 0.12154\n",
      ">5 f([-0.05222756  0.32234308]) = 0.10663\n",
      ">6 f([-0.03620086  0.30332769]) = 0.09332\n",
      ">7 f([-0.02165679  0.28463383]) = 0.08149\n",
      ">8 f([-0.00883663  0.26630707]) = 0.07100\n",
      ">9 f([0.00205801 0.24839209]) = 0.06170\n",
      ">10 f([0.01088844 0.23093228]) = 0.05345\n",
      ">11 f([0.01759677 0.2139692 ]) = 0.04609\n",
      ">12 f([0.02221425 0.19754214]) = 0.03952\n",
      ">13 f([0.02485859 0.18168769]) = 0.03363\n",
      ">14 f([0.02572196 0.16643933]) = 0.02836\n",
      ">15 f([0.02505339 0.15182705]) = 0.02368\n",
      ">16 f([0.02313917 0.13787701]) = 0.01955\n",
      ">17 f([0.02028406 0.12461125]) = 0.01594\n",
      ">18 f([0.01679451 0.11204744]) = 0.01284\n",
      ">19 f([0.01296436 0.10019867]) = 0.01021\n",
      ">20 f([0.00906264 0.08907337]) = 0.00802\n",
      ">21 f([0.00532366 0.07867522]) = 0.00622\n",
      ">22 f([0.00193919 0.06900318]) = 0.00477\n",
      ">23 f([-0.00094677  0.06005154]) = 0.00361\n",
      ">24 f([-0.00324034  0.05181012]) = 0.00269\n",
      ">25 f([-0.00489722  0.04426444]) = 0.00198\n",
      ">26 f([-0.00591902  0.03739604]) = 0.00143\n",
      ">27 f([-0.00634719  0.0311828 ]) = 0.00101\n",
      ">28 f([-0.00625503  0.02559933]) = 0.00069\n",
      ">29 f([-0.00573849  0.02061737]) = 0.00046\n",
      ">30 f([-0.00490679  0.01620624]) = 0.00029\n",
      ">31 f([-0.00387317  0.01233332]) = 0.00017\n",
      ">32 f([-0.00274675  0.00896449]) = 0.00009\n",
      ">33 f([-0.00162559  0.00606458]) = 0.00004\n",
      ">34 f([-0.00059149  0.00359785]) = 0.00001\n",
      ">35 f([0.0002934  0.00152838]) = 0.00000\n",
      ">36 f([ 0.00098821 -0.00017954]) = 0.00000\n",
      ">37 f([ 0.00147307 -0.00156101]) = 0.00000\n",
      ">38 f([ 0.00174746 -0.00265025]) = 0.00001\n",
      ">39 f([ 0.00182724 -0.00348028]) = 0.00002\n",
      ">40 f([ 0.00174089 -0.00408267]) = 0.00002\n",
      ">41 f([ 0.00152536 -0.00448737]) = 0.00002\n",
      ">42 f([ 0.00122173 -0.00472254]) = 0.00002\n",
      ">43 f([ 0.00087133 -0.00481438]) = 0.00002\n",
      ">44 f([ 0.00051228 -0.00478712]) = 0.00002\n",
      ">45 f([ 0.00017692 -0.00466292]) = 0.00002\n",
      ">46 f([-0.00011001 -0.00446188]) = 0.00002\n",
      ">47 f([-0.00033219 -0.004202  ]) = 0.00002\n",
      ">48 f([-0.00048176 -0.00389929]) = 0.00002\n",
      ">49 f([-0.00055861 -0.00356777]) = 0.00001\n",
      ">50 f([-0.00056912 -0.00321961]) = 0.00001\n",
      ">51 f([-0.00052452 -0.00286514]) = 0.00001\n",
      ">52 f([-0.00043908 -0.00251304]) = 0.00001\n",
      ">53 f([-0.0003283  -0.00217044]) = 0.00000\n",
      ">54 f([-0.00020731 -0.00184302]) = 0.00000\n",
      ">55 f([-8.95352320e-05 -1.53514076e-03]) = 0.00000\n",
      ">56 f([ 1.43050285e-05 -1.25002847e-03]) = 0.00000\n",
      ">57 f([ 9.67123406e-05 -9.89850279e-04]) = 0.00000\n",
      ">58 f([ 0.00015359 -0.00075587]) = 0.00000\n",
      ">59 f([ 0.00018407 -0.00054858]) = 0.00000\n",
      "Done!\n",
      "f([ 0.00018407 -0.00054858]) = 0.000000\n"
     ]
    }
   ],
   "source": [
    "# seed the pseudo random number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "# define the total iterations\n",
    "n_iter = 60\n",
    "# steps size\n",
    "alpha = 0.02\n",
    "# factor for average gradient\n",
    "beta1 = 0.8\n",
    "# factor for average squared gradient\n",
    "beta2 = 0.999\n",
    "# perform the gradient descent search with adam\n",
    "best, score = adam(objective, derivative, bounds, n_iter, alpha, beta1, beta2)\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (best, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-official",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
