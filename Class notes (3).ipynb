{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "architectural-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming #tokenize or segment -- nltk\n",
    "#vectorizing\n",
    "#Sentiment analysis --\" movie was exceptionally good\"\n",
    "#imdb website\n",
    "#imdb.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 importing the dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('F:/VIT COLLEGE/2nd SEM/MACHINE LEARNING/LAB/IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quantitative-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.['review'][0] -- creation of commas cc by attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dutch-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 data preparation -- Regular expression\n",
    "#getting rid of html tags and emilvs- if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alone-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming the Documents (Review Column)\n",
    "# working: work(stem) + ing(suffix)\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer() #Lancaster #Snowball # RegExp: singing = s\n",
    "\n",
    "def stemmer_tokenize(text):\n",
    " return[porter.stem(word) for word in text.split()] #word_tokenize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "overall-motion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'loev', 'coding.', 'henc', 'we', 'keep', 'do', 'code']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer_tokenize('We loev coding. Hence we keep doing coding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Vectorising the text data #stanfordnlp (converting text to numbers)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Countvertorizer\n",
    "tfidf = TfidfVectorizer(strip_accents = None, lowercase = False, tokenizer = stemmer_tokenize, use_idf= True)\n",
    "\n",
    "Y = df.sentiment.values\n",
    "X = tfidf.fit_transform(df.review) #learn vocabolory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Document Classification/Sentiment Analysis using Logistic Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1, shuff\n",
    "import pickle #(to create dump file)\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "logitCV = LogisticRegressionCV (cv =5, scoring = 'accuracy', max_iter = 100).fit(\n",
    "saved_model = open('saved_model.sav', 'wb') #create a file\n",
    "pickle.dump(logitCV, saved_model)\n",
    "saved_model.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 RUN THE SAVED MODEL\n",
    "filename = 'saved_model.sav'\n",
    "saved_logitCV = pickle.load(open(filename, 'rb'))\n",
    "saved_logitCV.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-heavy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
